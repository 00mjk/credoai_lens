{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credo Governance Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a comprehensive overview of how you can interact with the Credo AI Governance Platform.\n",
    "\n",
    "All the code shown here can be found on [github](https://github.com/credo-ai/credoai_lens/blob/develop/docs/notebooks/governance_integration.ipynb).\n",
    "\n",
    "\n",
    "Connecting Lens to the Governance App requires that you have already defined a Use-Case and registered a model to that use-case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glossary\n",
    "A list of useful concepts to keep in mind while\n",
    "- **Credo AI Platform**: Also referred to as simply \"platform\". The central AI governance/reporting Platform, found at [https://app.credo.ai/](https://app.credo.ai/)\n",
    "- **credoconfig**: configuration file to be copied in the user's home folder\n",
    "- **use_case_name**: The name of your Use Case as it is registered on Credo AI Platform\n",
    "- **policy_pack**: A set of responsible AI controls that a use case needs to satisfy. A use case can have multiple policy packs applied to it.\n",
    "- **policy_pack_key**: A unique identifier for a policy pack (where do we get this?)\n",
    "- **assessment_plan**: A set of evaluations that `Lens` needs to run in order to satisfy a policy pack requirements.\n",
    "- **evidence**: The output of a `Lens` evaluation, formatted specifically to be uploaded to the platform.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a config file\n",
    "This file contains all the necessary information to connect Lens to the Credo AI Platform.  \n",
    "\n",
    "The default location where Lens will look for it is your home directory (`~/.credoconfig`). The structure of the config should look like this\n",
    "\n",
    "```\n",
    "TENANT=<tenant name> # Example: credoai\n",
    "CREDO_URL=<your credo url> \n",
    "API_KEY=<your api key> # Example: JSMmd26...\n",
    "```\n",
    "\n",
    "To generate the config file, once you logged into the platform, click on your name icon (top left) and follow:  \n",
    "My Settings -> Tokens -> Plus Sign -> Generate  \n",
    "Immediately after generating the token, you will be given the possibility to download the config file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get your model ready\n",
    "Since a use case and model were already registered on the Platform already, we assume that a fitted model is available. In this tutorial we will emulate the modeling phase by running a quick script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model and df are defined by this script\n",
    "%run training_script.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Governance\n",
    "In this phase we create the Governance object with all the necessary information required to run a battery of assessments defined by your use case and policy pack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from credoai.governance import Governance\n",
    "gov = Governance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After initializing the `Governance` object, we need to register an assessment plan. This can be achieved in three ways:\n",
    "1. Using the `assessment_plan_url`. In the Platform: your_use_case -> Reports -> Your_policy_pack -> **ASSESSMENT PLAN** -> **Copy URL**\n",
    "2. Using the assessment plan json. Follow steps in 1., but click on **Download** as the last step. (more details in [Air Gap Environment](##Air-Gap-Environment))\n",
    "3. Using use_case_name and policy pack key as they are defined in the Platform\n",
    "\n",
    "In the tutorial we will follow 1. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'your_assessment_url'\n",
    "gov.register(assessment_plan_url=url)\n",
    "\n",
    "# Alternatively method 2.\n",
    "# gov.register(use_case_name='your_use_case_name', policy_pack_key='your_policy_pack_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Lens\n",
    "This part is very similar to a standard `Lens` run. See the quickstart notebook !!insert link!! for more general information on `Lens`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Create artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from credoai.artifacts import ClassificationModel, TabularData\n",
    "\n",
    "credo_model = ClassificationModel(\"credit_default_classifier\", model)\n",
    "test_data = TabularData(\n",
    "    name=\"UCI-credit-default-test\",\n",
    "    X=X_test,\n",
    "    y=y_test,\n",
    "    sensitive_features=sensitive_features_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from credoai.lens import Lens\n",
    "lens = Lens(\n",
    "    model=credo_model,\n",
    "    assessment_data=test_data,\n",
    "    governance=gov\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `Governance` is included in the initialization of Lens, there is no need to specify which evaluators to include in the pipeline. Under the hood, `Lens` converts the assessment plan contained in `gov` into a list of evaluators.\n",
    "\n",
    "A simple `lens.run()` is sufficient to run all the required assessments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the execution proceeded according to expectations, the evidences, i.e., the results of the assessments, can be sent to the `Governance` object and finally exported to the platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens.send_to_governance(True)\n",
    "gov.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! With just a few lines of code, a set of evidences documenting compliance to a set of controls defined by a policy pack has been uploaded to the Platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Air Gap Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you cannot interact with Credo AI's Governance App via the internet, this section is for you!\n",
    "\n",
    "Instead of Lens automating the communication between your assessment environment and governance, you will instead have to download an assessment plan, provide it to `Governance`, run `Lens` and finally upload the evidences (assessments results) to the platform.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Getting the assessment spec\n",
    "The asset that you have to get _from_ the governance app is the assessment plan. This can be found in:   \n",
    "\n",
    "your_use_case -> Reports -> Your_policy_pack -> **ASSESSMENT PLAN** -> **Download**  \n",
    "\n",
    "Once you download the assessments plan, you can pass it to the Governance object, see code below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gov.register(assessment_plan_file='your_assessment_file.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can also register the json in string form using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gov.register(assessment_plan='your_long_json_string_assessment_plan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "##### ???Is this still true???\n",
    "**Important Note On Data Registration in an air-gapped environment** \n",
    "When interacting with Credo AI's API you _only_ have to register a Use Case and Model within the platform - nothing needs to be done relating to data. Lens will handle registering your training/assessment data to the app \n",
    "However, when in an air-gapped environment you WILL need to register the training and validation data in the platform first. Otherwise Lens will fail.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting Results\n",
    "\n",
    "Lens can export evidences to file as a json object. This is generally useful if you want to store your results locally, but particularly useful if you are in an air gapped environment where you cannot access Credo AI's Governance Platform directly from your development environment.\n",
    "\n",
    "Doing this only requires a one line change in our current flow. We change the `export` argument from `Governance` to a local path:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-27 17:13:43,628 - lens - INFO - It is not registered, please register first\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To save the evidences locally\n",
    "gov.export('evidences_test.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the above will create a folder that you specified, if it doesn't exist. It will then create a json file with the assessment results, which can be uploaded to Credo AI's Governance Platform. This json file can be uploaded by going to:  \n",
    "\n",
    "your_use_case -> Reports -> Your_policy_pack -> **UPLOAD LENS EVIDENCE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.env2': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "507a61bde0a0183a71b2d35939f461921273a091e2cc4517af66dd70c4baafc9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
