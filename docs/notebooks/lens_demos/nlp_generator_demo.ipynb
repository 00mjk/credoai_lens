{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8423743-017a-4b8e-abb7-85bac0c96fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from credoai.lens import Lens, CredoModel, CredoData\n",
    "from credoai.assessment import NLPGeneratorAssessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffb1d0d3-00c5-4d73-b52e-818bb1fb0d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n",
      "Some weights of OpenAIGPTLMHeadModel were not initialized from the model checkpoint at openai-gpt and are newly initialized: ['lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import OpenAIGPTLMHeadModel, OpenAIGPTTokenizer, GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "tokenizer_gpt1 = OpenAIGPTTokenizer.from_pretrained('openai-gpt')\n",
    "model_gpt1 = OpenAIGPTLMHeadModel.from_pretrained('openai-gpt', pad_token_id=tokenizer_gpt1.eos_token_id)\n",
    "def gpt1_text_generator(prompt):\n",
    "    inputs = tokenizer_gpt1.encode(prompt, return_tensors='pt')\n",
    "    outputs = model_gpt1.generate(inputs, max_length=max(30, len(inputs[0])+1), do_sample=True)\n",
    "    response = tokenizer_gpt1.decode(outputs[0], skip_special_tokens=True)[len(prompt):]\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9d16a70-1428-4d1e-ac81-f1d2be554395",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/lens_full/lib/python3.9/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator LogisticRegression from version 1.0 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained toxicity assessment model loaded.\n",
      "Sentence Encoder loaded.\n"
     ]
    }
   ],
   "source": [
    "credo_model = CredoModel(name='gpt1',\n",
    "           model_config = {'generator_fun': gpt1_text_generator})\n",
    "\n",
    "assessment_spec = {'NLPGenerator': {'prompts': 'realtoxicityprompts_challenging_20'}}\n",
    "lens = Lens(model = credo_model,\n",
    "            spec = assessment_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ad656d-f8b8-4607-874a-e736e55a93af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Loaded the prompts dataset realtoxicityprompts_challenging_20\n",
      "INFO:absl:Performed prerun checks of generation and assessment functions\n",
      "INFO:absl:Performing Generation Iteration 1 of 1 with Generation Model gpt1\n"
     ]
    }
   ],
   "source": [
    "results = lens.run_assessments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd27b1d-dd14-4933-8990-702637c17790",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
