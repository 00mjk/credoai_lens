{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05f4ef89",
   "metadata": {},
   "source": [
    "# Word Embedding Models Bias Assessment with Lens\n",
    "Word embeddings models generate a real-valued vector representation of text data and are mainstream in many AI systems that involve natural language data. However, they have been claimed to exhibit a range of human-like social biases ([Garg et al. 2018](https://www.pnas.org/content/115/16/E3635)). This demo illustrates how Lens can be used to assess them for such biases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ff9723",
   "metadata": {},
   "source": [
    "### Find the code\n",
    "This notebook can be found on [github](https://github.com/credo-ai/credoai_lens/blob/develop/docs/notebooks/module_demos/fairness_nlp.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c1d9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from credoai.assessment.model_modules.fairness_nlp import NLPEmbeddingAnalyzer\n",
    "from credoai.utils.nlp_constants import OCCUPATIONS, ISLAM, CHRISTIAN\n",
    "from pytorch_transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e8d894",
   "metadata": {},
   "source": [
    "### Set up BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6944ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel.from_pretrained('bert-base-uncased',\n",
    "           output_hidden_states = True,)\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647fe2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://towardsdatascience.com/3-types-of-contextualized-word-embeddings-from-bert-using-transfer-learning-81fcefe3fe6d\n",
    "def bert_text_preparation(text, tokenizer):\n",
    "    \"\"\"Preparing the input for BERT\n",
    "    \n",
    "    Takes a string argument and performs\n",
    "    pre-processing like adding special tokens,\n",
    "    tokenization, tokens to ids, and tokens to\n",
    "    segment ids. All tokens are mapped to seg-\n",
    "    ment id = 1.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Text to be converted\n",
    "        tokenizer (obj): Tokenizer object\n",
    "            to convert text into BERT-re-\n",
    "            adable tokens and ids\n",
    "        \n",
    "    Returns:\n",
    "        list: List of BERT-readable tokens\n",
    "        obj: Torch tensor with token ids\n",
    "        obj: Torch tensor segment ids\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    segments_ids = [1]*len(indexed_tokens)\n",
    "\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "    return tokenized_text, tokens_tensor, segments_tensors\n",
    "\n",
    "def get_bert_embeddings(tokens_tensor, segments_tensors, model):\n",
    "    \"\"\"Get embeddings from an embedding model\n",
    "    \n",
    "    Args:\n",
    "        tokens_tensor (obj): Torch tensor size [n_tokens]\n",
    "            with token ids for each token in text\n",
    "        segments_tensors (obj): Torch tensor size [n_tokens]\n",
    "            with segment ids for each token in text\n",
    "        model (obj): Embedding model to generate embeddings\n",
    "            from token and segment ids\n",
    "    \n",
    "    Returns:\n",
    "        list: List of list of floats of size\n",
    "            [n_tokens, n_embedding_dimensions]\n",
    "            containing embeddings for each token\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Gradient calculation id disabled\n",
    "    # Model is in inference mode\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor, segments_tensors)\n",
    "        # Removing the first hidden state\n",
    "        # The first state is the input state\n",
    "        hidden_states = outputs[2][1:]\n",
    "\n",
    "    # Getting embeddings from the final BERT layer\n",
    "    token_embeddings = hidden_states[-1]\n",
    "    \n",
    "    # collapse tensor and conver tto numpy\n",
    "    return token_embeddings.squeeze().numpy()\n",
    "\n",
    "def get_bert_embedding(word):\n",
    "    tokenized_text, tokens_tensor, segments_tensors = bert_text_preparation(word, tokenizer)\n",
    "    return get_bert_embeddings(tokens_tensor, segments_tensors, model)[1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e617ea",
   "metadata": {},
   "source": [
    "### Run Assessment\n",
    "\n",
    "This module evaluates model embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bb3624",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_assessment = NLPEmbeddingAnalyzer(get_bert_embedding)\n",
    "nlp_assessment.run('male', 'female')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb3b393",
   "metadata": {},
   "source": [
    "Custom categories can be included. A category is a set of words that reflect the category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf824a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "superheroes = {'superheroes': ['batman', 'superman', 'marvel', 'dc', 'wonderwoman', 'justice league']}\n",
    "nlp_assessment.set_comparison_categories(include_default=False, custom_categories=superheroes)\n",
    "nlp_assessment.run('male', 'female')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d9605d",
   "metadata": {},
   "source": [
    "Custom categories can be single words. Below we evaluate the association between the male/female access and a number of occupation labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad25f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_assessment.set_comparison_categories(custom_categories={k:k for k in OCCUPATIONS})\n",
    "pd.Series(nlp_assessment.run('male', 'female')).sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260b3055",
   "metadata": {},
   "source": [
    "The group categories can also be changed. Each group category is associated with a set of words, which is used to define the average *group embedding vector*. The default is male/female, but other groups can be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6befedd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_assessment.set_comparison_categories()\n",
    "nlp_assessment.set_group_embeddings({'islam': ISLAM, \n",
    "                                  'christian': CHRISTIAN})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8431f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_assessment.run('islam', 'christian')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
