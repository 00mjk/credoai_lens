{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81b97cd3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Connecting with the Credo AI Governance Platform\n",
    "\n",
    "## Overview\n",
    "Connecting with the Credo AI Governance Platform is straightforward using Lens. After following this tutorial you'll be up and running!\n",
    "\n",
    "### Find the code\n",
    "This notebook can be found on [github](https://github.com/credo-ai/credoai_lens/blob/develop/docs/notebooks/governance_integration.ipynb).\n",
    "\n",
    "**Table of Contents**\n",
    "\n",
    "1. [Setup](#Setup)\n",
    "1. [Using Lens](#Using-Lens)\n",
    "    1. [Exporting to Credo AI's Governance Platform from Lens](#Exporting-to-Credo-AI's-Governance-Platform-from-Lens)\n",
    "    2. [CredoGovernance](#Credo-Governance-Artifact)\n",
    "    3. [Registering a model while assessing it](#Registering-a-model-while-assessing-it)\n",
    "1. [Air Gap Environment](#Air-Gap-Environment)\n",
    "    1. [Getting the assessment spec](#Getting-the-assessment-spec) \n",
    "    2. [Exporting Results](#Exporting-Results)\n",
    "1. [Explicitly registering model and data artifacts](#Explicitly-registering-model-and-data-artifacts)\n",
    "    1. [Registering a Project and Model](#Registering-a-Project-and-Model)\n",
    "\n",
    "### Config File\n",
    "First, ensure you have a config file somewhere on your computer named \".credoconfig\". The default location where Lens will look for it in your home directory (`~/.credoconfig`). The structure of the config should look like this\n",
    "\n",
    "```\n",
    "TENANT=<tenant name> # Example: credoai\n",
    "API_KEY=<your api key> # Example: JSMmd26...\n",
    "```\n",
    "\n",
    "This config gives Lens API access to the Governance Platform.\n",
    "\n",
    "### Connecting to a particular model, dataset, or Use Case\n",
    "\n",
    "Lens connects to the Governance Platform via a `CredoGovernance` object. This specifies the IDs of the Use Case, model and data you want to associate your assessments with. The IDs are found in the url of your Use Case or model.\n",
    "\n",
    "For instance, the Use Case ID is found here: `...credo.com/use-cases/{use_case_id}`\n",
    "\n",
    "And the model Id is found here: `...credo.com/models/{model_id}`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8f0aca",
   "metadata": {},
   "source": [
    "## Train your Model\n",
    "\n",
    "Some quick setup... This is all of your datascience work before assessment and integration with Credo AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a704197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for example data and model training\n",
    "from credoai.data import fetch_creditdefault\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Base Lens imports\n",
    "import credoai.lens as cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc88b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_creditdefault()\n",
    "X = data['data'].drop(columns=['SEX'])\n",
    "y = data['target']\n",
    "sensitive_feature = data['data']['SEX']\n",
    "\n",
    "model = GradientBoostingClassifier()\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cf87db",
   "metadata": {},
   "source": [
    "## Using Lens\n",
    "\n",
    "This is going to be familiar if you've gone through our quickstart tutorial! The only addition is the use of a `CredoGovernance` object.\n",
    "\n",
    "### Credo Governance Artifact\n",
    "The CredoGovernance object has a few functionalities.\n",
    "\n",
    "* The ability to get an alignment spec from the Use Case (created during the aligned process). The alignment spec is either downloaded straight from the Governance Platform, or supplied as a json file for air gap deployment. This alignment spec can be supplemented (or overwritten) with an alignment spec you define in code and pass to Lens.\n",
    "* The ability to register models and projects.\n",
    "* Encoding the IDs of governance objects so Lens can easily export metrics and reports.\n",
    "\n",
    "\\** **Attention** \\**\n",
    "\n",
    "The metrics and reports will _either_ be exported to the model and data specified in by `CredoGovernance` (using the `model_id` and `data_id` arguments) OR a new model and data will be registered on your CredoGovernance platform automatically, which will then be used for export.\n",
    "\n",
    "With that said, let's see how this works in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7af9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "credo_model = cl.CredoModel(name='credit_default_classifier',\n",
    "                            model=model)\n",
    "\n",
    "credo_data = cl.CredoData(name='UCI-credit-default',\n",
    "                          X=X, \n",
    "                          y=y.astype(int),\n",
    "                          sensitive_features=sensitive_feature)\n",
    "\n",
    "# New artifact for governance\n",
    "credo_governance = cl.CredoGovernance(use_case_id=\"your-use-case-id\",\n",
    "                                      model_id=\"your-model-id\"\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eccda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the metrics that will be used by the FairnessBase assessment. \n",
    "# This spec will supplement (or overide!) whatever spec is \n",
    "# pulled down from the Governance Platform\n",
    "alignment_spec = {\n",
    "    'FairnessBase': {'metrics': ['precision_score']}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a60052d",
   "metadata": {},
   "source": [
    "### Interacting with Credo AI's Governance Platform from Lens\n",
    "\n",
    "In addition to the model and data, we can pass the CredoGovernance object. This is how Lens knows which Use Case, model and/or data to interacts with. If you are running assessments on multiple models, you'll create a separate `CredoGovernance` object (and separate Lens instances) for each.\n",
    "\n",
    "That's it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24830c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from credoai.assessment import FairnessBaseAssessment\n",
    "lens = cl.Lens(model=credo_model,\n",
    "               governance=credo_governance,\n",
    "               assessments = [FairnessBaseAssessment()],\n",
    "               data=credo_data,\n",
    "               spec=alignment_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8496e7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just add the export option and the metrics will be sent to the Governance Platform.\n",
    "lens.run_assessments(export=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cec3526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reports can be exported too!\n",
    "lens.create_reports(export=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434b6551",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Registering a model while assessing it\n",
    "\n",
    "**No Governance Info? No Problem**\n",
    "\n",
    "Sometimes you may not want to create a `CredoGovernance` object before using Lens. There may not be an `assessment spec` that you have to pull down for instance. Or you may not have a model registered yet in the Governance Platform to receive your assessments.\n",
    "\n",
    "If you still want to log a model assessment, Lens will take care of registering a new model and project on Credo AI's Governance Platform first. The below will create a project called `an example model project` and log the model `an example model ` under it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6744db98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from credoai.assessment import FairnessBaseAssessment\n",
    "credo_model = cl.CredoModel(name='an example model',\n",
    "                            model=model)\n",
    "\n",
    "lens = cl.Lens(model=credo_model,\n",
    "               assessments = [FairnessBaseAssessment()],\n",
    "               data=credo_data,\n",
    "               spec=alignment_spec)\n",
    "lens.run_assessments(export=True)\n",
    "lens.create_reports(export=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13de77a",
   "metadata": {},
   "source": [
    "The governance object is created for you, and can be interrogated or used later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8890971",
   "metadata": {},
   "outputs": [],
   "source": [
    "gov = lens.get_governance()\n",
    "gov.get_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936b6b7d",
   "metadata": {},
   "source": [
    "\\** **Attention** \\**\n",
    "\n",
    "\n",
    "Note that if you run the above a second time, registration will fail. Project and model names must be unique! If you would like to run Lens again, sending the results to the same project/model you can get the governance info by running `lens.get_governance`, and passing that to the governance object of another Lens instance.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b473213",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "previously_created_governance = lens.get_governance()\n",
    "lens = cl.Lens(model=credo_model,\n",
    "               assessments = [FairnessBaseAssessment()],\n",
    "               data=credo_data,\n",
    "               spec=alignment_spec,\n",
    "               governance = previously_created_governance)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633a18ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Air Gap Environment\n",
    "\n",
    "If you cannot interact with Credo AI's Governance Platfrom via the internet, this section is for you!\n",
    "\n",
    "Instead of Lens automating the communication between your assessment environment and governance, you will instead have to download assets and upload them. \n",
    "\n",
    "### Getting the assessment spec\n",
    "The asset that you may have to get _from_ the governance platform is the assessment spec. This can be found under the \"Technical Requirements\" of your Use Case. Once you download the assessments spec, you can read it with a CredoGovernance object:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a5ac67",
   "metadata": {},
   "outputs": [],
   "source": [
    "gov = cl.CredoGovernance()\n",
    "# you must explicitly retrieve the assessment spec \n",
    "# in an air gapped environment!\n",
    "gov.retrieve_assessment_spec('{path to assessment spec}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26781cc",
   "metadata": {},
   "source": [
    "Following that, you can pass the governance object to Lens as normal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f1b3bc",
   "metadata": {},
   "source": [
    "### Exporting Results\n",
    "\n",
    "Lens can export assessment results to file as a json object. This is generally useful if you want to store your results locally, but particularly useful if you are in an air gapped environment where you cannot access Credo AI's Governance Platform directly from your development environment.\n",
    "\n",
    "Doing this only requires a one line change in our current flow. We change the `export` argument from `True` to a local path:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1aa0097",
   "metadata": {},
   "outputs": [],
   "source": [
    "lens.run_assessments(export='{path where assessments should be exported}')\n",
    "\n",
    "# reports are exported to file in an analagous way.\n",
    "# lens.create_reports(export='{path where assessments should be exported}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad34f162",
   "metadata": {},
   "source": [
    "Running the above will create a folder that you specified, if it doesn't exist. Within that folder each assessment's output will be saved as a separate json file. This json file can be uploaded by going to the **Asset Store** of your Model on the Governance Platform, pressing the purple \"+\" button under \"Metrics\" and uploading the json. Reports should be uploaded under \"Chart\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699e2259",
   "metadata": {},
   "source": [
    "## Explicitly registering model and data artifacts\n",
    "\n",
    "While Lens will take care of registering a model and data for you if no `model_id` or `data_id` is provided, you can also manually register models yourself using a `CredoGovernance` object.\n",
    "\n",
    "This is helpful if you want to run Lens multiple times, or want to have more control over the names of your project and/or model. \n",
    "* First, you create a CredoGovernance object\n",
    "* Second register your project and model\n",
    "* Third, pass to Lens as normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e66846",
   "metadata": {},
   "source": [
    "### Registering a Project and Model\n",
    "\n",
    "**Models** are organized under **Projects**. If you register a Model, a Project will be automatically created to house the Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01d3ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gov = cl.CredoGovernance()\n",
    "gov.register_model(model_name='my_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf3dbba",
   "metadata": {},
   "source": [
    "If a Project already exists that you'd like to use (registering a model _to_ that project), supply the Project ID to the `CredoGovernance` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb1141b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gov = cl.CredoGovernance(model_project_id = 'existing project')\n",
    "gov.register_model(model_name='my_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e5ad94",
   "metadata": {},
   "source": [
    "If you want to register a new project and control its name, register the Project explicitly before registering the Model.\n",
    "\n",
    "Note - if the model already exists, and is associated with a project, the project will be registered without a model! (The model already is registered to another project)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bb3061",
   "metadata": {},
   "outputs": [],
   "source": [
    "gov = cl.CredoGovernance()\n",
    "gov.register_project('my_project')\n",
    "gov.register_model(model_name='my_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a258d4f7-d9a1-40cf-8c69-89cac57db8dd",
   "metadata": {},
   "source": [
    "**Datasets** can be registered analogously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fd9d2e-36ad-4bb5-9884-7718af56355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gov.register_dataset('my_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4ac4f8-5f4b-438d-bc59-2173a0527b42",
   "metadata": {},
   "source": [
    "**Use Cases** can also be used. If CredoGovernance has a Use Case ID, the model will automatically be associated with that Use Case ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac34ddf5-e53e-4082-9370-63b27dd52055",
   "metadata": {},
   "outputs": [],
   "source": [
    "gov = cl.CredoGovernance(use_case_id_id=\"your-use-case-id\")\n",
    "gov.register_model(model_name='my_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
