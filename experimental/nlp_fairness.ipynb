{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a03303-1275-4e60-9acf-2a5987ab8afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from pytorch_transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from credoai.utils.common import wrap_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496740fd-0c1c-41b3-859d-d3d596576498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0473cb6d-28c8-4ad4-b6a9-d39fc214cfee",
   "metadata": {},
   "source": [
    "## Set up word sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94399d85-a020-4a16-a514-e596a4d52fd2",
   "metadata": {},
   "source": [
    "Fairness Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3839391-76f7-4e0a-9eb4-e3167914c2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Garg, N., Schiebinger, L., Jurafsky, D., & Zou, J. (2018). Word embeddings quantify 100 years of gender and ethnic stereotypes. \n",
    "man_words = ['he','son','his','him','father','man','boy','himself',\n",
    "             'male','brother','sons','fathers','men','boys','males',\n",
    "             'brothers','uncle,uncles','nephew','nephews']\n",
    "\n",
    "woman_words = ['she','daughter','hers','her','mother','woman','girl','herself',\n",
    "               'female','sister','daughters','mothers','women', 'girls',\n",
    "               'femen','sisters','aunt','aunts','niece','nieces']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877d7991-b61c-4868-8366-0c99eb4ddd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Singh, A., Chen, J., Zhang, L., Rasekh, A., Golbin, I., & Rao, A. (2021). Independent Ethical Assessment of Text Classification Models: \n",
    "# A Hate Speech Detection Case Study. In arXiv [cs.CY]. arXiv. https://doi.org/10.1145/1122445.1122456\n",
    "\n",
    "# these words seem quite problematic for genders!\n",
    "male_words = [\"cowboy\", \"cowboys\", \"cameramen\", \"cameraman\", \n",
    "        \"busboy\",\"busboys\", \"bellboy\", \"bellboys\", \n",
    "        \"barman\", \"barmen\", \"tailor\", \"tailors\",\"prince\", \n",
    "        \"princes\", \"governor\", \"governors\", \"adultor\", \n",
    "        \"adultors\", \"god\",\"gods\", \"host\", \"hosts\", \"abbot\", \n",
    "        \"abbots\", \"actor\", \"actors\", \"bachelor\",\"bachelors\", \n",
    "        \"baron\", \"barons\", \"beau\", \"beaus\", \"bridegroom\", \"bridegrooms\", \n",
    "        \"brother\", \"brothers\", \"duke\", \"dukes\", \"emperor\", \"emperors\",\"enchanter\", \n",
    "        \"father\", \"fathers\", \"fiance\", \"fiances\", \"priest\", \"priests\",\"gentleman\", \n",
    "        \"gentlemen\", \"grandfather\", \"grandfathers\", \"headmaster\", \n",
    "        \"headmasters\", \"hero\", \"heros\", \"lad\", \"lads\", \"landlord\", \n",
    "        \"landlords\",\"male\", \"males\", \"man\", \"men\", \"manservant\", \n",
    "        \"manservants\", \"marquis\", \"masseur\", \"masseurs\", \"master\", \n",
    "        \"masters\", \"monk\", \"monks\",\"nephew\", \"nephews\", \"priest\", \n",
    "        \"priests\", \"sorcerer\", \"sorcerers\", \"step-father\", \"stepfathers\", \n",
    "        \"stepson\", \"stepsons\", \"steward\", \"stewards\", \"un-cle\", \"uncles\", \n",
    "        \"waiter\", \"waiters\", \"widower\", \"widowers\", \"wizard\",\"wizards\", \n",
    "        \"airman\", \"airmen\", \"boy\", \"boys\", \"groom\", \"grooms\", \"businessman\", \n",
    "        \"businessmen\", \"chairman\", \"chairmen\", \"dude\", \"dudes\",\n",
    "       \"dad\", \"dads\", \"daddy\", \"daddies\", \"son\", \"sons\", \"guy\", \"guys\", \n",
    "        \"grandson\",\"grandsons\", \"guy\", \"guys\", \"he\", \"himself\", \"him\", \n",
    "        \"his\", \"husband\", \"hus-bands\", \"king\", \"kings\", \"lord\", \"lords\", \n",
    "        \"sir\", \"sir\", \"mr.\", \"mr.\", \"policeman\",\"spokesman\", \"spokesmen\"\n",
    "]\n",
    "\n",
    "female_words = [\"cowgirl\", \"cowgirls\", \"camerawomen\", \"camerawoman\",\"busgirl\", \n",
    "          \"busgirls\", \"bellgirl\", \"bellgirls\", \"barwoman\", \"barwomen\",\n",
    "          \"seamstress\", \"seamstress\", \"princess\", \"princesses\", \n",
    "          \"governess\", \"gov-ernesses\", \"adultress\", \"adultresses\", \n",
    "          \"godess\", \"godesses\", \"hostess\",\"hostesses\", \"abbess\", \n",
    "          \"abbesses\", \"actress\", \"actresses\", \"spinster\", \"spinsters\", \n",
    "          \"baroness\", \"barnoesses\", \"belle\", \"belles\", \"bride\", \"brides\", \n",
    "          \"sister\", \"sisters\", \"duchess\", \"duchesses\", \"empress\", \n",
    "          \"empresses\", \"enchantress\",\"mother\", \"mothers\", \"fiancee\", \n",
    "          \"fiancees\", \"nun\", \"nuns\", \"lady\", \"ladies\",\"grandmother\", \n",
    "          \"grandmothers\", \"headmistress\", \"headmistresses\",\"heroine\", \n",
    "          \"heroines\", \"lass\", \"lasses\", \"landlady\", \"landladies\", \"female\",\n",
    "          \"females\", \"woman\", \"women\", \"maidservant\", \"maidservants\", \n",
    "          \"marchioness\", \"masseuse\", \"masseuses\", \"mistress\", \"mistresses\", \n",
    "          \"nun\",\"nuns\", \"niece\", \"nieces\", \"priestess\", \"priestesses\", \"sorceress\", \n",
    "          \"sorceresses\", \"stepmother\", \"stepmothers\", \"stepdaughter\", \"stepdaughters\",\n",
    "          \"stewardess\", \"stewardesses\", \"aunt\", \"aunts\", \"waitress\", \"waitresses\",\n",
    "          \"widow\", \"widows\", \"witch\", \"witches\", \"airwoman\", \"airwomen\", \"girl\",\n",
    "          \"girls\", \"bride\", \"brides\", \"businesswoman\", \"businesswomen\", \n",
    "          \"chairwoman\", \"chairwomen\", \"chick\", \"chicks\", \"mom\", \"moms\", \"mommy\",\n",
    "          \"mommies\", \"daughter\", \"daughters\", \"gal\", \"gals\", \"granddaughter\",\n",
    "          \"granddaughters\", \"girl\", \"girls\", \"she\", \"herself\", \"her\", \"her\", \"wife\",\n",
    "          \"wives\", \"queen\", \"queens\", \"lady\", \"ladies\", \"ma'am\", \"miss\", \"mrs.\", \n",
    "          \"ms.\",\"policewoman\", \"spokeswoman\", \"spokeswomen\"]\n",
    "\n",
    "islam_words = [\"allah\", \"ramadan\", \"turban\", \"emir\", \"salaam\", \"sunni\", \"ko-ran\",\n",
    "               \"imam\", \"sultan\", \"prophet\", \"veil\", \"ayatollah\", \"shiite\", \"mosque\",\n",
    "               \"islam\", \"sheik\", \"muslim\", \"muhammad\"\n",
    "]\n",
    "\n",
    "christian_words = [\"baptism\", \"messiah\", \"catholicism\", \"resurrection\",\"christianity\", \n",
    "                   \"salvation\", \"protestant\", \"gospel\", \"trinity\", \"jesus\", \"christ\",\n",
    "                   \"christian\", \"cross\", \"catholic\", \"church\", \"christians\", \"catholics\"]\n",
    "\n",
    "# names\n",
    "chinese_words = [\"chung\", \"liu\", \"wong\", \"huang\", \"ng\", \"hu\", \"chu\", \"chen\",\"lin\", \"liang\", \"wang\", \"wu\", \"yang\", \"tang\", \"chang\", \"hong\", \"li\"]\n",
    "hispanic_words = [\"ruiz\", \"alvarez\", \"vargas\", \"castillo\", \"gomez\", \"soto\", \"gon-zalez\", \"sanchez\", \"rivera\", \"mendoza\", \"martinez\", \"torres\", \"rodriguez\",\"perez\", \"lopez\", \"medina\", \"diaz\", \"garcia\", \"castro\", \"cruz\"]\n",
    "white_words = [\"harris\", \"nelson\", \"robinson\", \"thompson\", \"moore\", \"wright\",\"anderson\", \"clark\", \"jackson\", \"taylor\", \"scott\", \"davis\", \"allen\", \"adams\",\"lewis\", \"williams\", \"jones\", \"wilson\", \"martin\", \"johnson\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7d36ba-2a49-4fe9-bfcf-2f09342c7ca8",
   "metadata": {},
   "source": [
    "Comparison sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08976966-6d14-4dd3-8661-bbb1493874e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Garg, N., Schiebinger, L., Jurafsky, D., & Zou, J. (2018). Word embeddings quantify 100 years of gender and ethnic stereotypes.\n",
    "neutral_adjectives = [\n",
    "    \"disorganized\", \"devious\", \"impressionable\", \"circumspect\", \"impassive\", \n",
    "    \"aimless\", \"effeminate\", \"unfathomable\", \"fickle\", \"unprincipled\", \n",
    "    \"inoffensive\", \"reactive\", \"providential\", \"resentful\", \"bizarre\", \"impractical\",\n",
    "    \"sarcastic\", \"misguided\", \"imitative\", \"pedantic\", \"venomous\", \"erratic\", \"insecure\", \n",
    "    \"resourceful\", \"neurotic\", \"forgiving\", \"profligate\", \"whimsical\", \"assertive\", \n",
    "    \"incorruptible\", \"individualistic\", \"faithless\", \"disconcerting\", \"barbaric\", \n",
    "    \"hypnotic\", \"vindictive\", \"observant\", \"dissolute\", \"frightening\", \"complacent\", \n",
    "    \"boisterous\", \"pretentious\", \"disobedient\", \"tasteless\", \"sedentary\", \"sophisticated\", \n",
    "    \"regimental\", \"mellow\", \"deceitful\", \"impulsive\", \"playful\", \"sociable\", \"methodical\", \n",
    "    \"willful\", \"idealistic\", \"boyish\", \"callous\", \"pompous\", \"unchanging\", \"crafty\", \n",
    "    \"punctual\", \"compassionate\", \"intolerant\", \"challenging\", \"scornful\", \"possessive\", \n",
    "    \"conceited\", \"imprudent\", \"dutiful\", \"lovable\", \"disloyal\", \"dreamy\", \"appreciative\", \n",
    "    \"forgetful\", \"unrestrained\", \"forceful\", \"submissive\", \"predatory\", \"fanatical\", \"illogical\",\n",
    "    \"tidy\", \"aspiring\", \"studious\", \"adaptable\", \"conciliatory\", \"artful\", \"thoughtless\", \n",
    "    \"deceptive\", \"frugal\", \"reflective\", \"insulting\", \"unreliable\", \"stoic\", \"hysterical\", \n",
    "    \"rustic\", \"inhibited\", \"outspoken\", \"unhealthy\", \"ascetic\", \"skeptical\", \"painstaking\",\n",
    "    \"contemplative\", \"leisurely\", \"sly\", \"mannered\", \"outrageous\", \"lyrical\", \"placid\", \n",
    "    \"cynical\", \"irresponsible\", \"vulnerable\", \"arrogant\", \"persuasive\", \"perverse\", \n",
    "    \"steadfast\", \"crisp\", \"envious\", \"naive\", \"greedy\", \"presumptuous\", \"obnoxious\",\n",
    "    \"irritable\", \"dishonest\", \"discreet\", \"sporting\", \"hateful\", \"ungrateful\", \"frivolous\", \n",
    "    \"reactionary\", \"skillful\", \"cowardly\", \"sordid\", \"adventurous\", \"dogmatic\", \"intuitive\", \n",
    "    \"bland\", \"indulgent\", \"discontented\", \"dominating\", \"articulate\", \"fanciful\", \n",
    "    \"discouraging\", \"treacherous\", \"repressed\", \"moody\", \"sensual\", \"unfriendly\", \n",
    "    \"optimistic\", \"clumsy\", \"contemptible\", \"focused\", \"haughty\", \"morbid\", \"disorderly\", \n",
    "    \"considerate\", \"humorous\", \"preoccupied\", \"airy\", \"impersonal\", \"cultured\", \"trusting\", \n",
    "    \"respectful\", \"scrupulous\", \"scholarly\", \"superstitious\", \"tolerant\", \"realistic\", \n",
    "    \"malicious\", \"irrational\", \"sane\", \"colorless\", \"masculine\", \"witty\", \"inert\", \n",
    "    \"prejudiced\", \"fraudulent\", \"blunt\", \"childish\", \"brittle\", \"disciplined\", \"responsive\",\n",
    "    \"courageous\", \"bewildered\", \"courteous\", \"stubborn\", \"aloof\", \"sentimental\", \"athletic\", \n",
    "    \"extravagant\", \"brutal\", \"manly\", \"cooperative\", \"unstable\", \"youthful\", \"timid\", \"amiable\", \n",
    "    \"retiring\", \"fiery\", \"confidential\", \"relaxed\", \"imaginative\", \"mystical\", \"shrewd\", \n",
    "    \"conscientious\", \"monstrous\", \"grim\", \"questioning\", \"lazy\", \"dynamic\", \"gloomy\", \n",
    "    \"troublesome\", \"abrupt\", \"eloquent\", \"dignified\", \"hearty\", \"gallant\", \"benevolent\", \n",
    "    \"maternal\", \"paternal\", \"patriotic\", \"aggressive\", \"competitive\", \"elegant\", \"flexible\", \n",
    "    \"gracious\", \"energetic\", \"tough\", \"contradictory\", \"shy\", \"careless\", \"cautious\", \n",
    "    \"polished\", \"sage\", \"tense\", \"caring\", \"suspicious\", \"sober\", \"neat\", \"transparent\", \n",
    "    \"disturbing\", \"passionate\", \"obedient\", \"crazy\", \"restrained\", \"fearful\", \"daring\", \n",
    "    \"prudent\", \"demanding\", \"impatient\", \"cerebral\", \"calculating\", \"amusing\", \"honorable\", \n",
    "    \"casual\", \"sharing\", \"selfish\", \"ruined\", \"spontaneous\", \"admirable\", \"conventional\", \n",
    "    \"cheerful\", \"solitary\", \"upright\", \"stiff\", \"enthusiastic\", \"petty\", \"dirty\", \n",
    "    \"subjective\", \"heroic\", \"stupid\", \"modest\", \"impressive\", \"orderly\", \"ambitious\", \n",
    "    \"protective\", \"silly\", \"alert\", \"destructive\", \"exciting\", \"crude\", \"ridiculous\",\n",
    "    \"subtle\", \"mature\", \"creative\", \"coarse\", \"passive\", \"oppressed\", \"accessible\", \n",
    "    \"charming\", \"clever\", \"decent\", \"miserable\", \"superficial\", \"shallow\", \"stern\", \n",
    "    \"winning\", \"balanced\", \"emotional\", \"rigid\", \"invisible\", \"desperate\", \"cruel\",\n",
    "    \"romantic\", \"agreeable\", \"hurried\", \"sympathetic\", \"solemn\", \"systematic\", \"vague\", \n",
    "    \"peaceful\", \"humble\", \"dull\", \"expedient\", \"loyal\", \"decisive\", \"arbitrary\", \"earnest\", \n",
    "    \"confident\", \"conservative\", \"foolish\", \"moderate\", \"helpful\", \"delicate\", \"gentle\", \n",
    "    \"dedicated\", \"hostile\", \"generous\", \"reliable\", \"dramatic\", \"precise\", \"calm\", \n",
    "    \"healthy\", \"attractive\", \"artificial\", \"progressive\", \"odd\", \"confused\", \"rational\", \n",
    "    \"brilliant\", \"intense\", \"genuine\", \"mistaken\", \"driving\", \"stable\", \"objective\", \n",
    "    \"sensitive\", \"neutral\", \"strict\", \"angry\", \"profound\", \"smooth\", \"ignorant\", \"thorough\",\n",
    "    \"logical\", \"intelligent\", \"extraordinary\", \"experimental\", \"steady\", \"formal\", \"faithful\", \n",
    "    \"curious\", \"reserved\", \"honest\", \"busy\", \"educated\", \"liberal\", \"friendly\", \"efficient\", \n",
    "    \"sweet\", \"surprising\", \"mechanical\", \"clean\", \"critical\", \"criminal\", \"soft\", \"proud\", \n",
    "    \"quiet\", \"weak\", \"anxious\", \"solid\", \"complex\", \"grand\", \"warm\", \"slow\", \"false\", \n",
    "    \"extreme\", \"narrow\", \"dependent\", \"wise\", \"organized\", \"pure\", \"directed\", \"dry\", \n",
    "    \"obvious\", \"popular\", \"capable\", \"secure\", \"active\", \"independent\", \"ordinary\", \"fixed\",\n",
    "    \"practical\", \"serious\", \"fair\", \"understanding\", \"constant\", \"cold\", \"responsible\", \n",
    "    \"deep\", \"religious\", \"private\", \"simple\", \"physical\", \"original\", \"working\", \"strong\", \n",
    "    \"modern\", \"determined\", \"open\", \"political\", \"difficult\", \"knowledge\", \"kind\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985dfedb-c859-49cf-9337-cab0b6940075",
   "metadata": {},
   "source": [
    "## Set up GLOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5ac812-f6d1-4fce-8698-aa95802ebbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict = {}\n",
    "with open(\"../data/glove.6B.300d.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict[word] = vector\n",
    "        \n",
    "def get_glove_embedding(word):\n",
    "    return embeddings_dict.get(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aefa50-d6dc-41e2-8c84-5f503450fafe",
   "metadata": {},
   "source": [
    "## Set up BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ca72e8-58a4-4fe3-8a6c-426a1dd242af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel.from_pretrained('bert-base-uncased',\n",
    "           output_hidden_states = True,)\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c410bbcc-95c0-40c3-909c-600e56259513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://towardsdatascience.com/3-types-of-contextualized-word-embeddings-from-bert-using-transfer-learning-81fcefe3fe6d\n",
    "def bert_text_preparation(text, tokenizer):\n",
    "    \"\"\"Preparing the input for BERT\n",
    "    \n",
    "    Takes a string argument and performs\n",
    "    pre-processing like adding special tokens,\n",
    "    tokenization, tokens to ids, and tokens to\n",
    "    segment ids. All tokens are mapped to seg-\n",
    "    ment id = 1.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Text to be converted\n",
    "        tokenizer (obj): Tokenizer object\n",
    "            to convert text into BERT-re-\n",
    "            adable tokens and ids\n",
    "        \n",
    "    Returns:\n",
    "        list: List of BERT-readable tokens\n",
    "        obj: Torch tensor with token ids\n",
    "        obj: Torch tensor segment ids\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    segments_ids = [1]*len(indexed_tokens)\n",
    "\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "    return tokenized_text, tokens_tensor, segments_tensors\n",
    "\n",
    "def get_bert_embeddings(tokens_tensor, segments_tensors, model):\n",
    "    \"\"\"Get embeddings from an embedding model\n",
    "    \n",
    "    Args:\n",
    "        tokens_tensor (obj): Torch tensor size [n_tokens]\n",
    "            with token ids for each token in text\n",
    "        segments_tensors (obj): Torch tensor size [n_tokens]\n",
    "            with segment ids for each token in text\n",
    "        model (obj): Embedding model to generate embeddings\n",
    "            from token and segment ids\n",
    "    \n",
    "    Returns:\n",
    "        list: List of list of floats of size\n",
    "            [n_tokens, n_embedding_dimensions]\n",
    "            containing embeddings for each token\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Gradient calculation id disabled\n",
    "    # Model is in inference mode\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor, segments_tensors)\n",
    "        # Removing the first hidden state\n",
    "        # The first state is the input state\n",
    "        hidden_states = outputs[2][1:]\n",
    "\n",
    "    # Getting embeddings from the final BERT layer\n",
    "    token_embeddings = hidden_states[-1]\n",
    "    \n",
    "    # collapse tensor and conver tto numpy\n",
    "    return token_embeddings.squeeze().numpy()\n",
    "\n",
    "def get_bert_embedding(word):\n",
    "    tokenized_text, tokens_tensor, segments_tensors = bert_text_preparation(word, tokenizer)\n",
    "    return get_bert_embeddings(tokens_tensor, segments_tensors, model)[1, :]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694a1066-47fd-414e-9547-e37aa7c91758",
   "metadata": {},
   "source": [
    "### Other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e73e11-c0c6-4e7d-acca-396a9ed946eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_words(words, embedding_fun=get_bert_embedding):\n",
    "    words = wrap_list(words)\n",
    "    tmp = []\n",
    "    for word in words:\n",
    "        emb = embedding_fun(word)\n",
    "        if emb is not None:\n",
    "            tmp.append(emb)\n",
    "    mat = np.vstack(tmp)\n",
    "    # normalize to unit norm\n",
    "    return mat/np.linalg.norm(mat, axis=1)[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5b89cd-65dc-4a16-ad8c-6479bddfb769",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def singh_embedding_bias(group_embeddings, comparison_embedding):\n",
    "    \"\"\"\n",
    "    This method calculates embedding bias as \n",
    "    \"\"\"\n",
    "    comparison_relations = [cosine_similarity(embedding, comparison_embedding).mean(0)\n",
    "                            for embedding in group_embeddings]\n",
    "    pairwise_comparisons = []\n",
    "    for vec1, vec2 in combinations(comparison_relations, 2):\n",
    "        pairwise_comparisons.append(abs(vec1-vec2).mean())\n",
    "    return np.mean(pairwise_comparisons)\n",
    "    \n",
    "    \n",
    "def garg_embedding_bias(group_embeddings, comparison_embedding):\n",
    "    # average embeddings for a group\n",
    "    group_embeddings = [embedding.mean(0)[None,:] for embedding in group_embeddings]\n",
    "    # similarities\n",
    "    comparison_relations = [cosine_similarity(embedding, comparison_embedding)\n",
    "                            for embedding in group_embeddings]\n",
    "    pairwise_comparisons = []\n",
    "    for vec1, vec2 in combinations(comparison_relations, 2):\n",
    "        pairwise_comparisons.append(abs(vec1-vec2).mean())\n",
    "    return np.mean(pairwise_comparisons)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2c74e9-1f52-419c-ad6f-c569996fe51a",
   "metadata": {},
   "source": [
    "## Create embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ebefe0-8159-4a32-833b-ae7ab63e6323",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedders = {'bert': get_bert_embedding, 'glove': get_glove_embedding}\n",
    "group_words = {'ethnicity': [white_words, hispanic_words, chinese_words],\n",
    "               'gender': [male_words, female_words],\n",
    "               'sex': [man_words, woman_words],\n",
    "               'he-she': [['he'], ['she']],\n",
    "               'religion': [islam_words, christian_words]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a03b140-731e-4e4b-a773-e5be58f16e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = {}\n",
    "for name, embedder in embedders.items():\n",
    "    embeddings[name] = {}\n",
    "    for group, word_lists in group_words.items():\n",
    "        embeddings[name][group] = [embed_words(words, embedder) for words in word_lists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d5910e-e59b-4662-911f-646ddc22b138",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings['glove']['neutral'] = embed_words(neutral_adjectives, embedders['glove'])\n",
    "embeddings['bert']['neutral'] = embed_words(neutral_adjectives, embedders['bert'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124dd02d-1d9a-4c15-97bd-4814ee5d9532",
   "metadata": {},
   "source": [
    "## Recreate results\n",
    "\n",
    "Recreate results from the Singh et al. Hate Speech case study paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2503b2-2cd5-4d38-97fd-493dff076e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tuples = [('bert', 'singh'), ('bert', 'garg'), ('glove', 'singh'), ('glove', 'garg')]\n",
    "results = pd.DataFrame(columns=group_words.keys(), index=pd.MultiIndex.from_tuples(tuples, names=[\"embedder\", \"method\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8885327e-be0d-4de3-a02d-bf0c49e7ee0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fun_name, bias_fun in [('garg', garg_embedding_bias), ('singh', singh_embedding_bias)]:\n",
    "    for embedder, group_embeddings in embeddings.items():\n",
    "        for group in group_words.keys():\n",
    "            bias = bias_fun(group_embeddings[group], group_embeddings['neutral'])\n",
    "            results.loc[(embedder, fun_name), group] = bias\n",
    "results.query('method==\"singh\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e52806-d823-4b57-9030-bf231da7b17f",
   "metadata": {},
   "source": [
    "## New Analyses\n",
    "\n",
    "Few changes here. \n",
    "* For one, in Garg et al. they first average the \"group embeddings\" to create one vector representing each group and relates that to the neutral words. Singh related each individual word to the neutral words first, before averaging. These create somewhat different results which should be quantified.\n",
    "* Garg et al. also preserve direction because they only do binary comparisons.\n",
    "\n",
    "We will use Garg et al, both because it is simpler and better cited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566eb7e7-2cbe-4ea8-b0f8-173483d39502",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.query('method==\"garg\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec74aef-b8a0-4e4d-854f-ecf8fa0a37f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.query('method==\"singh\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68273138-cb06-4e62-b030-32caa1dd0c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    abs(results.query('method==\"garg\"').droplevel('method') \n",
    "     - results.query('method==\"singh\"').droplevel('method')\n",
    "    ) \n",
    "    / results.query('method==\"garg\"').droplevel('method')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdfb1a8-6745-4c76-a6d0-7908f4c55a1d",
   "metadata": {},
   "source": [
    "### Bias analysis for two groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a3dafe-52ba-486e-b6e7-b8b7e04a4999",
   "metadata": {},
   "source": [
    "**Sanity check**\n",
    "\n",
    "Directionally correct. BERT has much less \"bias\". Is that because it is less biased? Is it instead a \"curse of dimensionality\", and all vectors are further apart in a higher dimensional space? All distances approach 0 in a larger dimensional space.\n",
    "\n",
    "Questions - how to normalize? To themselves maybe? Does this prevent comparisons between models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1808aebb-af1a-4c92-9de8-8010dff34d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "female_biased = ['she', 'breast', 'nurse', 'ovarian cancer']\n",
    "for word in female_biased:\n",
    "    try:\n",
    "        glove_val = garg_directional_bias(embeddings['glove']['he-she'][0], embeddings['glove']['he-she'][1], get_glove_embedding(word)[None,:])\n",
    "    except TypeError:\n",
    "        glove_val = float('inf')\n",
    "    bert_val = garg_directional_bias(embeddings['bert']['he-she'][0], embeddings['bert']['he-she'][1], get_bert_embedding(word)[None,:])\n",
    "    print(f'{word}: glove: {glove_val:.3f}, bert: {bert_val:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509cdfbe-6fa8-476b-afea-57aeb705ff26",
   "metadata": {},
   "outputs": [],
   "source": [
    "male_biased = ['he', 'penis', 'carpenter', 'prostate cancer']\n",
    "for word in male_biased:\n",
    "    try:\n",
    "        glove_val = garg_directional_bias(embeddings['glove']['he-she'][0], embeddings['glove']['he-she'][1], get_glove_embedding(word)[None,:])\n",
    "    except TypeError:\n",
    "        glove_val = float('inf')\n",
    "    bert_val = garg_directional_bias(embeddings['bert']['he-she'][0], embeddings['bert']['he-she'][1], get_bert_embedding(word)[None,:])\n",
    "    print(f'{word}: glove: {glove_val:.3f}, bert: {bert_val:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319bcba2-4e06-4713-8cd8-aec6271ff18d",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "\n",
    "To deal with the issues above we need a standard frame of reference. Seems the most obvious frame of reference are the word groups themselves.\n",
    "\n",
    "Procedure:\n",
    "* Define word sets for each group (male, female)\n",
    "* Define word set for comparison group (e.g., STEM professionals)\n",
    "* Create an average vector for each group by averaging embeddings for their group set.\n",
    "* Compare the average vectors to the group vectors to get a \"bias\" score for each group. You should find that, when compared with the \"male\" words, the bias is in the \"male\" direction. Same for female. These will be taken as the maximum \"male\" bias you can get and maximum \"female\" bias.\n",
    "* Compute the bias vs the neutral words and normalize to that min and max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01775e46-95cd-415b-bc05-661844606b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_directional_bias(group1, group2, comparison_embedding, verbose=False):\n",
    "    max_bias = garg_directional_bias(group1, group2, group1)\n",
    "    min_bias = garg_directional_bias(group1, group2, group2)\n",
    "    assert max_bias>0 and min_bias<0\n",
    "    if verbose:\n",
    "        print(f'Max Bias: {max_bias:.3f}\\nMin Bias: {min_bias:.3f}')\n",
    "    bias = garg_directional_bias(group1, group2, comparison_embedding)\n",
    "    normalized_bias = ((bias-min_bias)/(max_bias-min_bias)*2)-1\n",
    "    return bias, normalized_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580e8ee0-5690-4574-91f4-5b61706dbedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "normalized_directional_bias(embeddings['bert']['he-she'][0], \n",
    "                            embeddings['bert']['he-she'][1], \n",
    "                            get_bert_embedding('carpenter')[None,:], \n",
    "                            True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7f4f2f-f076-4270-89d3-5ce0569aa0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "normalized_directional_bias(embeddings['glove']['he-she'][0], \n",
    "                            embeddings['glove']['he-she'][1],  \n",
    "                            get_glove_embedding('carpenter')[None,:],\n",
    "                           True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafe40f4-693f-4bf2-b83e-cbd88daad5aa",
   "metadata": {},
   "source": [
    "## Toolkit\n",
    "\n",
    "Create suite of comparison categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e7d187-03da-4b22-a70f-46e1e47c78ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from credoai.nlp_fairness import NLPFairnessToolkit\n",
    "from credoai.utils.nlp_constants import OCCUPATIONS, ISLAM, CHRISTIAN\n",
    "from pytorch_transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcd0588-56c2-439f-8789-64b7886219a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel.from_pretrained('bert-base-uncased',\n",
    "           output_hidden_states = True,)\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacf416b-cd5c-4bdb-8117-5c2afa726658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://towardsdatascience.com/3-types-of-contextualized-word-embeddings-from-bert-using-transfer-learning-81fcefe3fe6d\n",
    "def bert_text_preparation(text, tokenizer):\n",
    "    \"\"\"Preparing the input for BERT\n",
    "    \n",
    "    Takes a string argument and performs\n",
    "    pre-processing like adding special tokens,\n",
    "    tokenization, tokens to ids, and tokens to\n",
    "    segment ids. All tokens are mapped to seg-\n",
    "    ment id = 1.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Text to be converted\n",
    "        tokenizer (obj): Tokenizer object\n",
    "            to convert text into BERT-re-\n",
    "            adable tokens and ids\n",
    "        \n",
    "    Returns:\n",
    "        list: List of BERT-readable tokens\n",
    "        obj: Torch tensor with token ids\n",
    "        obj: Torch tensor segment ids\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    segments_ids = [1]*len(indexed_tokens)\n",
    "\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "    return tokenized_text, tokens_tensor, segments_tensors\n",
    "\n",
    "def get_bert_embeddings(tokens_tensor, segments_tensors, model):\n",
    "    \"\"\"Get embeddings from an embedding model\n",
    "    \n",
    "    Args:\n",
    "        tokens_tensor (obj): Torch tensor size [n_tokens]\n",
    "            with token ids for each token in text\n",
    "        segments_tensors (obj): Torch tensor size [n_tokens]\n",
    "            with segment ids for each token in text\n",
    "        model (obj): Embedding model to generate embeddings\n",
    "            from token and segment ids\n",
    "    \n",
    "    Returns:\n",
    "        list: List of list of floats of size\n",
    "            [n_tokens, n_embedding_dimensions]\n",
    "            containing embeddings for each token\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Gradient calculation id disabled\n",
    "    # Model is in inference mode\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor, segments_tensors)\n",
    "        # Removing the first hidden state\n",
    "        # The first state is the input state\n",
    "        hidden_states = outputs[2][1:]\n",
    "\n",
    "    # Getting embeddings from the final BERT layer\n",
    "    token_embeddings = hidden_states[-1]\n",
    "    \n",
    "    # collapse tensor and conver tto numpy\n",
    "    return token_embeddings.squeeze().numpy()\n",
    "\n",
    "def get_bert_embedding(word):\n",
    "    tokenized_text, tokens_tensor, segments_tensors = bert_text_preparation(word, tokenizer)\n",
    "    return get_bert_embeddings(tokens_tensor, segments_tensors, model)[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda09653-1874-4d07-847a-28aabe940bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_toolkit = NLPFairnessToolkit(get_bert_embedding)\n",
    "nlp_toolkit.evaluate_embeddings('male', 'female')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471b7c4a-ae7b-4942-a9a5-5f4f598df891",
   "metadata": {},
   "source": [
    "Custom categories can be included. A category is a set of words that reflect the category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd36a0e1-f507-4e55-bb19-da2f6c5217ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "superheroes = {'superheroes': ['batman', 'superman', 'marvel', 'dc', 'wonderwoman', 'justice league']}\n",
    "nlp_toolkit.set_comparison_categories(include_default=False, custom_categories=superheroes)\n",
    "nlp_toolkit.evaluate_embeddings('male', 'female')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1d95f6-793c-43d0-94f7-82a70c40c9ae",
   "metadata": {},
   "source": [
    "Custom categories can be single words. Below we evaluate the association between the male/female access and a number of occupation labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3357c9db-f19a-4577-b276-3445fcdb0e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_toolkit.set_comparison_categories(custom_categories={k:k for k in OCCUPATIONS})\n",
    "pd.Series(nlp_toolkit.evaluate_embeddings('male', 'female')).sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04f2334-ba37-4a5c-9211-5f8752c544f8",
   "metadata": {},
   "source": [
    "The group categories can also be changed. Each group category is associated with a set of words, which is used to define the average *group embedding vector*. The default is male/female, but other groups can be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d764b58d-a151-4816-843c-5960c5aa8410",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_toolkit.set_comparison_categories()\n",
    "nlp_toolkit.set_group_embeddings({'islam': ISLAM, \n",
    "                                  'christian': CHRISTIAN})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24404ba5-4eb6-4651-94d1-5525a0ea91a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_toolkit.evaluate_embeddings('islam', 'christian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d045a729-9cd4-455f-8a95-a18c1acec276",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
